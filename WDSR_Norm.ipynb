{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "WDSR-Norm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih5rvn3t2Uxc",
    "colab_type": "text"
   },
   "source": [
    "##Clone the git repo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "It0Rei_ozkL5",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "outputId": "a3fd6073-a1fc-4635-f7c2-0f557d27e39d"
   },
   "source": [
    "!git clone https://github.com/ofrimasad/WDSR-Norm.git\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Cloning into 'WDSR-Norm'...\n",
      "remote: Enumerating objects: 50, done.\u001b[K\n",
      "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
      "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
      "remote: Total 50 (delta 17), reused 46 (delta 13), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (50/50), done.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-VCPXvG2Zpd",
    "colab_type": "text"
   },
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-9RXSXZkzurw",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!pip install future"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y8CPIe72HNG",
    "colab_type": "text"
   },
   "source": [
    "after This block you will need to click the restart (button at the bottom of the execution pane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAiY-c-V2mDG",
    "colab_type": "text"
   },
   "source": [
    "## Download and extract dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoJ5pWx-dPSF",
    "colab_type": "text"
   },
   "source": [
    "Create a directory for the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qYQgZzMV0Zc_",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!mkdir /content/WDSR-Norm/data\n",
    "!mkdir /content/WDSR-Norm/data/dvi2k"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWvpOI5N3I3p",
    "colab_type": "text"
   },
   "source": [
    "**Download** - This part may take a while"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_1JP-7wGC6vL",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X2.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X3.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X2.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X3.zip -P /content/WDSR-Norm/data/div2k/\n",
    "!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_bicubic_X4.zip -P /content/WDSR-Norm/data/div2k/"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLvyLSvIdetm",
    "colab_type": "text"
   },
   "source": [
    "**Extract**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bAEWzy-h0ojj",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_train_HR.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_train_LR_bicubic_X2.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_train_LR_bicubic_X3.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_train_LR_bicubic_X4.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_valid_HR.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_valid_LR_bicubic_X2.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_valid_LR_bicubic_X3.zip -d /content/WDSR-Norm/data/div2k/\n",
    "!unzip -q /content/WDSR-Norm/data/div2k/DIV2K_valid_LR_bicubic_X4.zip -d /content/WDSR-Norm/data/div2k/"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9Qhg6eddi9p",
    "colab_type": "text"
   },
   "source": [
    "##Run a Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "8p3Tbx8cWEFA",
    "colab": {}
   },
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/WDSR-Norm/results"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTArXOhhdotq",
    "colab_type": "text"
   },
   "source": [
    "##Train the models \n",
    "WDSR-A\n",
    "WDSR-Deconv\n",
    "WDSR-Norm-Deconv"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Px1kNaBxEOri",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "618f730d-20bb-44a2-c472-25134d82a203"
   },
   "source": [
    "!PYTHONPATH=/content/WDSR-Norm python /content/WDSR-Norm/train.py \\\n",
    "--dataset-dir \"/content/WDSR-Norm/data/div2k/\" --output-dir \"/content/WDSR-Norm/results/output\" \\\n",
    "--model \"WDSR-A\" --scale 2 --n-feats 32 --n-res-blocks 16 --expansion-ratio 4 \\\n",
    "--res-scale 1.0 --lr 1e-3 "
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "==============================\n",
      "model          : WDSR-A\n",
      "parameters     : 1190100\n",
      "scale          : 2\n",
      "n-feats        : 32\n",
      "n-res-blocks   : 16\n",
      "expansion-ratio: 4\n",
      "res-scale      : 1.0\n",
      "==============================\n",
      "\n",
      "[epoch: 1/300]\n",
      "train: 100% 16000/16000 [04:28<00:00, 141.09it/s, loss=5.8450]\n",
      "valid: 100% 100/100 [01:03<00:00,  2.11it/s, loss=3.9860]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 32.7526\n",
      "* best PSNR: 32.7526 @ epoch: 1\n",
      "\n",
      "[epoch: 2/300]\n",
      "train: 100% 16000/16000 [02:52<00:00, 92.56it/s, loss=4.1348] \n",
      "valid: 100% 100/100 [00:53<00:00,  2.13it/s, loss=3.8044]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.1470\n",
      "* best PSNR: 33.1470 @ epoch: 2\n",
      "\n",
      "[epoch: 3/300]\n",
      "train: 100% 16000/16000 [02:34<00:00, 103.47it/s, loss=3.9961]\n",
      "valid: 100% 100/100 [00:52<00:00,  2.14it/s, loss=3.7647]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.2685\n",
      "* best PSNR: 33.2685 @ epoch: 3\n",
      "\n",
      "[epoch: 4/300]\n",
      "train: 100% 16000/16000 [02:24<00:00, 157.28it/s, loss=3.8805]\n",
      "valid: 100% 100/100 [00:52<00:00,  2.12it/s, loss=3.8498]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.2025\n",
      "* best PSNR: 33.2685 @ epoch: 3\n",
      "\n",
      "[epoch: 5/300]\n",
      "train: 100% 16000/16000 [02:20<00:00, 113.76it/s, loss=3.8460]\n",
      "valid: 100% 100/100 [00:52<00:00,  2.14it/s, loss=3.6207]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.5405\n",
      "* best PSNR: 33.5405 @ epoch: 5\n",
      "\n",
      "[epoch: 6/300]\n",
      "train: 100% 16000/16000 [02:18<00:00, 115.79it/s, loss=3.8223]\n",
      "valid: 100% 100/100 [00:52<00:00,  2.13it/s, loss=3.6080]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.5743\n",
      "* best PSNR: 33.5743 @ epoch: 6\n",
      "\n",
      "[epoch: 7/300]\n",
      "train: 100% 16000/16000 [02:17<00:00, 116.42it/s, loss=3.7985]\n",
      "valid: 100% 100/100 [00:52<00:00,  2.13it/s, loss=3.5550]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.7065\n",
      "* best PSNR: 33.7065 @ epoch: 7\n",
      "\n",
      "[epoch: 8/300]\n",
      "train: 100% 16000/16000 [02:14<00:00, 118.78it/s, loss=3.7458]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.13it/s, loss=3.5168]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.8075\n",
      "* best PSNR: 33.8075 @ epoch: 8\n",
      "\n",
      "[epoch: 9/300]\n",
      "train: 100% 16000/16000 [02:14<00:00, 118.96it/s, loss=3.7025]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.14it/s, loss=3.5463]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.7608\n",
      "* best PSNR: 33.8075 @ epoch: 8\n",
      "\n",
      "[epoch: 10/300]\n",
      "train: 100% 16000/16000 [02:13<00:00, 120.00it/s, loss=3.7101]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.13it/s, loss=3.5724]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.7113\n",
      "* best PSNR: 33.8075 @ epoch: 8\n",
      "\n",
      "[epoch: 11/300]\n",
      "train: 100% 16000/16000 [02:13<00:00, 180.78it/s, loss=3.6765]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.15it/s, loss=3.4553]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.9574\n",
      "* best PSNR: 33.9574 @ epoch: 11\n",
      "\n",
      "[epoch: 12/300]\n",
      "train: 100% 16000/16000 [02:13<00:00, 120.10it/s, loss=3.6300]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.13it/s, loss=3.4887]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.8756\n",
      "* best PSNR: 33.9574 @ epoch: 11\n",
      "\n",
      "[epoch: 13/300]\n",
      "train: 100% 16000/16000 [02:14<00:00, 186.14it/s, loss=3.6568]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.13it/s, loss=3.4687]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.9456\n",
      "* best PSNR: 33.9574 @ epoch: 11\n",
      "\n",
      "[epoch: 14/300]\n",
      "train: 100% 16000/16000 [02:12<00:00, 210.37it/s, loss=3.5957]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.13it/s, loss=3.4675]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.9467\n",
      "* best PSNR: 33.9574 @ epoch: 11\n",
      "\n",
      "[epoch: 15/300]\n",
      "train: 100% 16000/16000 [02:13<00:00, 119.45it/s, loss=3.5911]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.13it/s, loss=3.4562]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.9871\n",
      "* best PSNR: 33.9871 @ epoch: 15\n",
      "\n",
      "[epoch: 16/300]\n",
      "train: 100% 16000/16000 [02:13<00:00, 120.18it/s, loss=3.6191]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.14it/s, loss=3.4359]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 34.0271\n",
      "* best PSNR: 34.0271 @ epoch: 16\n",
      "\n",
      "[epoch: 17/300]\n",
      "train: 100% 16000/16000 [02:12<00:00, 121.12it/s, loss=3.6274]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.10it/s, loss=3.4211]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 34.0704\n",
      "* best PSNR: 34.0704 @ epoch: 17\n",
      "\n",
      "[epoch: 18/300]\n",
      "train: 100% 16000/16000 [02:13<00:00, 120.21it/s, loss=3.6105]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.17it/s, loss=3.4316]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 33.9798\n",
      "* best PSNR: 34.0704 @ epoch: 17\n",
      "\n",
      "[epoch: 19/300]\n",
      "train: 100% 16000/16000 [02:12<00:00, 120.50it/s, loss=3.6045]\n",
      "valid: 100% 100/100 [00:51<00:00,  2.14it/s, loss=3.3932]\n",
      "* learning rate: 0.001\n",
      "* PSNR: 34.1206\n",
      "* best PSNR: 34.1206 @ epoch: 19\n",
      "\n",
      "[epoch: 20/300]\n",
      "train:  95% 15264/16000 [02:09<00:04, 170.98it/s, loss=3.5567]"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}